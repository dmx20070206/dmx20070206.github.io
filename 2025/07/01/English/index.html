<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="记录为了保研面试读的英文文章">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <title>英语训练 |  Hexo</title>
  
    <link rel="apple-touch-icon" sizes="57x57" href="/images/DMX_cat.jpg/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/images/DMX_cat.jpg/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/images/DMX_cat.jpg/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/images/DMX_cat.jpg/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/images/DMX_cat.jpg/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/images/DMX_cat.jpg/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/images/DMX_cat.jpg/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/DMX_cat.jpg/apple-touch-icon-180x180.png">
    <link rel="apple-touch-icon" sizes="167x167" href="/images/DMX_cat.jpg/apple-touch-icon-167x167.png">
  
  
    <link rel="shortcut icon" href="/images/DMX_cat.jpg">
  
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <main class="main">
    
	<header id="header" class="header">

	<div class="container">
		<nav class="navbar d-flex align-items-center">
			<a class="brand" href="/">
				<img class="logo lazyload" data-src="/images/DMX_cat.jpg" alt="Hexo" role="img">
			</a>
			<ul class="main-nav">
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/">首页</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/stories">故事</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/archives">博客</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/about">关于</a>
  </li>
  
</ul>
		</nav>
		<a id="mobile-nav-toggle">
			<span class="mobile-nav-toggle-bar"></span>
			<span class="mobile-nav-toggle-bar"></span>
			<span class="mobile-nav-toggle-bar"></span>
		</a>
	</div>
</header>

    <section>
      <div class="container">
  <article id="post-English" class="article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
  
  <div class="article-cover mb-5">
    
  
    
      <img class="article-cover-img lazyload" data-src="/images/others/%E4%B9%9D%E6%97%A51.jpg" itemprop="image">
    
  

  </div>
  
  <div class="article-inner">
    
    <header class="article-header">
      
      
  
    <h1 class="article-title" itemprop="name">
      英语训练
    </h1>
  

      <div class="article-meta">
        <time class="text-gray" datetime="2025-06-30T16:00:00.000Z" itemprop="datePublished">
  2025-07-01
</time>
        
      </div>
      
    </header>
    
    <div class="article-entry" itemprop="articleBody">
      <p>记录为了保研面试读的英文文章</p>
<span id="more"></span>

<hr>
<link rel="stylesheet" href="/css/GPU_TEE.css">

<h3 id="Exposing-the-Guardrails-Reverse-Engineering-and-Jailbreaking-Safety-Filters-in-DALL·E-Text-to-Image-Pipelines"><a href="#Exposing-the-Guardrails-Reverse-Engineering-and-Jailbreaking-Safety-Filters-in-DALL·E-Text-to-Image-Pipelines" class="headerlink" title="Exposing the Guardrails: Reverse-Engineering and Jailbreaking Safety Filters in DALL·E Text-to-Image Pipelines"></a>Exposing the Guardrails: Reverse-Engineering and Jailbreaking Safety Filters in DALL·E Text-to-Image Pipelines</h3><blockquote>
<p>Villa C, Mirza S, Pöpper C. Exposing the Guardrails: Reverse-Engineering and Jailbreaking Safety Filters in DALL· E Text-to-Image Pipelines[J].</p>
</blockquote>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>We investigate the specific design and implementation of safety guardrails in black-box text-to-image (T2I) models, sucas DALL·E, which are implemented to prevent potential misuse from generating harmful image content. Specifically, wintroduce a novel timing-based side-channel analysis approach to reverse engineer the safety mechanisms of DALL·E models. Bmeasuring and analyzing the differential response times of these systems, we reverse-engineer the architecture of previouslunknown cascading safety filters at various stages of the T2I pipeline. Our analysis reveals key takeaways by contrastinsafety mechanisms in DALL·E 2 and DALL·E 3: DALL·E 2 uses blocklist-based filtering, whereas DALL·E 3 employs an LLM-baseprompt revision stage to improve image quality and filter harmful content. We find discrepancies between the LLM’s languagunderstanding and the CLIP embedding used for image generation, which we exploit to develop a negation-based jailbreakinattack. We further uncover gaps in the multilingual coverage of safety measures, which render DALL·E 3 vulnerable to a neclass of low-resource language attacks for T2I systems. Lastly, we outline six distinct countermeasures techniques anresearch directions to address our findings. This work emphasizes the challenges of aligning the diverse components of thessystems and underscores the need to improve the consistency and robustness of guardrails across the entire T2I pipeline.</p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>black box</strong></td>
<td>黑盒</td>
</tr>
<tr>
<td><strong>reverse engineer</strong></td>
<td>逆向工程</td>
</tr>
<tr>
<td><strong>cascading safety filters</strong></td>
<td>级联安全过滤器</td>
</tr>
<tr>
<td><strong>blocklist-based filtering</strong></td>
<td>黑名单过滤</td>
</tr>
<tr>
<td><strong>negation-based jailbreaking attack</strong></td>
<td>基于否定的越狱攻击</td>
</tr>
<tr>
<td><strong>low-resource language attacks</strong></td>
<td>低资源语言攻击</td>
</tr>
<tr>
<td>discrepancies</td>
<td>差异</td>
</tr>
<tr>
<td>contrast</td>
<td>对比</td>
</tr>
<tr>
<td>countermeasures</td>
<td>对策</td>
</tr>
<tr>
<td>multilingual</td>
<td>多语言的</td>
</tr>
<tr>
<td>render</td>
<td>呈现</td>
</tr>
<tr>
<td>guardrails</td>
<td>防护栏</td>
</tr>
</tbody></table>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>Text-to-image (T2I) models, such as DALL-E, Stable Diffusion, and Midjourney, have gained immense popularity by enabling users to generate realistic images from textual descriptions. These AI platforms have seen rapid adoption in real-world products, including Microsoft Designer and ad platforms from Google and Meta, revolutionizing the way users create and interact with visual content. However, the widespread use of T2I models has also raised concerns about their potential for generating harmful content. These models can produce sensitive Not-Safe-for-Work (NSFW) images, such as depicting violence, nudity, and child-inappropriate material, as well as disturbing, hateful, and politically charged images. Despite efforts by developers to implement safety guardrails, unsafe synthetic images continue to proliferate across both mainstream and fringe social networks. Communities such as Unstable Diffusion, which focus on generating sexual content, have attracted tens of thousands of members. Moreover, AI-generated variants of notorious memes are being used to spread hateful ideologies. As T2I models become more sophisticated, minimizing safety risks is paramount. Since the launch of DALL·E 2, users have created an average of 34 million images daily, and the recently introduced DALL·E 3 is accessible to millions of users through API and ChatGPT interfaces. However, little is known about the specific design and implementation of its safety filters, as this information has not been publicly documented by the developers. Prior work on red teaming of safety guardrails has primarily focused on open-source models such as Stable Diffusion and concluded the black-box security-by-obscurity approach to be insufficient. Given the enterprise-grade hardware and model capabilities accessible to users who bypass safety mechanisms in frontier models such as DALL·E, the potential for harm is significantly amplified compared to open-source alternatives. Therefore, understanding and evaluating the effectiveness of DALL·E’s safety measures is crucial to mitigate the risks associated with its misuse and ensure the responsible deployment of this powerful technology.
    In this paper, we present a novel approach to reverse-engineer and empirically map the cascading safety guardrails of DALL·E models using time-based side-channel analysis. Our methodology allows us to gain insights into the multi-stage filtering process, from user prompting to the final generated output. Through our analysis, we identify previously unknown filters and shed light on the differences in safety mechanisms between DALL·E 2 and DALL·E 3. Notably, we discover that DALL·E 3 incorporates a large language model (LLM)-based implicit filter to soften harmful prompts, while DALL·E 2 relies on conventional block-list and other more traditional filtering mechanics. Building upon our reverse-engineering of safety guardrails, we explore potential vulnerabilities and propose novel jailbreaking attacks specific to T2I models. Using low-resource-language and negation attacks, we exploit the limitations of the safety filters in handling less common languages and negated phrases. Finally, we draw upon our experimental findings to produce tangible countermeasure solutions that mitigate the timing side-channel and jailbreaking attacks.
    In summary, our contributions in this work are:
    <br>
    1. We present the first reverse-engineering of the black-box cascading safety guardrails in DALL·E models using a novel time-based side-channel, providing insights into a multi-stage filtering process, identifying previously unknown blocking or modifying filters, and enabling a feedback channel that adaptive attacks may exploit.
    <br>
    2. We synthesize key takeaways for T2I system security by juxtaposing safety mechanisms present in DALL·E 2 and DALL·E 3, notably the incorporation of an LLM-based implicit filter in DALL·E 3 to soften harmful prompts, in contrast to the conventional blocklist and similarity-based filtering in DALL·E 2.
    <br>
    3. We introduce novel jailbreaking attacks specific to T2I models, namely T2I negation and low-resource-language attacks, which exploit the limitations of safety filters in handling negated phrases and less common languages.
    <br>
    4. We provide an actionable list of six countermeasure recommendations for T2I systems to prevent attacks and enumerate directions for future defense research.</p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>red teaming</strong></td>
<td>红队测试</td>
</tr>
<tr>
<td><strong>enterprise-grade</strong></td>
<td>企业级</td>
</tr>
<tr>
<td><strong>feedback channel</strong></td>
<td>反馈通道</td>
</tr>
<tr>
<td><strong>adaptive attacks</strong></td>
<td>自适应攻击</td>
</tr>
<tr>
<td>depict</td>
<td>描绘</td>
</tr>
<tr>
<td>nudity</td>
<td>裸露</td>
</tr>
<tr>
<td>disturbing</td>
<td>恐怖的，令人不安的</td>
</tr>
<tr>
<td>synthetic</td>
<td>合成的，人工的</td>
</tr>
<tr>
<td>proliferate</td>
<td>激增，蔓延</td>
</tr>
<tr>
<td>fringe</td>
<td>边缘的，极端的</td>
</tr>
<tr>
<td>ideologies</td>
<td>思想意识形态</td>
</tr>
<tr>
<td>sophisticated</td>
<td>复杂的，精密的</td>
</tr>
<tr>
<td>paramount</td>
<td>极为重要的</td>
</tr>
<tr>
<td>frontier</td>
<td>前沿，边疆</td>
</tr>
<tr>
<td>mitigate</td>
<td>减轻，缓解</td>
</tr>
<tr>
<td>empirically</td>
<td>经验证的，经验上</td>
</tr>
<tr>
<td>incorporate</td>
<td>纳入，包含</td>
</tr>
<tr>
<td>implicit</td>
<td>隐含的</td>
</tr>
<tr>
<td>negated</td>
<td>否定的</td>
</tr>
<tr>
<td>phrase</td>
<td>短语，措辞</td>
</tr>
<tr>
<td>tangible</td>
<td>具体的，切实的</td>
</tr>
<tr>
<td>juxtaposing</td>
<td>并置，比较</td>
</tr>
</tbody></table>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>We begin by providing contextual background on harmful content generation, the T2I (Text-to-Image) model architecture, and safety filters. The interpretation of harm in image-based content varies across cultures, regions, and countries, making it difficult to classify and categorize content. Previous work has highlighted the lack of research on the taxonomy of AI-generated harms in imagery. T2I models have traditionally been deployed in a typical architecture: input text (prompts) are delivered to a pre-trained model, which processes the text using models like CLIP or BERT. The input is then encoded into vector-based embedding representations. These embeddings serve as input for image generation models, including diffusion and autoregressive models, to generate the final output image. In this paradigm, numerous safety filters are integrated throughout the components of the T2I pipeline, as shown in Figure 1. These filters can be configured to either outright reject problematic inputs or trigger transformations to the provided prompt.
    <br>
    1. Text-based safety filters operate on the input prompt or its embedding representation (Filters 1-3 in Fig. 1). Simple filtering strategies work on a keyword basis, where certain words such as "bloody" or "naked" are always rejected. While easy to implement, these filters can be circumvented by using grammatical negations or finding similar uncensored words. More sophisticated strategies can use multidimensional vector embeddings of the input text and perform similarity checks with sensitive content. These similarity-based filtering mechanisms can be bypassed using strategies outlined by Rando et al.
    <br>
    2. Post-processing filters, the second type of safety filter commonly implemented in deployment models, operate on the output generated by the T2I model (Filter 4 in Fig. 1). These safety filters can be image classifiers designed to detect harmful content in generated images and prevent them from being delivered to the user. More sophisticated filtering strategies at this stage may also incorporate the input text alongside the output image to determine whether an image is harmful. This filter type attempts to mitigate attacks that bypass the textual filter and produce harmful results.
    <br>
    The introduction of the state-of-the-art DALL·E 3 model extends the previous deployment architecture by adding a language model into the image generation pipeline. This language model is instructed to expand the user prompt to make it more descriptive for the image model, and additional image descriptions have been shown to significantly improve the generation quality. These revised prompts are included in the response returned to the user, allowing for debugging and prompt engineering. A filtering characteristic introduced by the language model is its ability to directly refuse problematic prompts according to its own alignment. These LLM refusals can be detected (Filter 2 in Fig. 1) and result in an error message returned to the user. This refusal functionality is described in the DALL·E 3 System Card, which details the adversarial evaluation performed by OpenAI before releasing the model. Given the stochastic nature of large language models, this content refusal filter may cause non-deterministic variance between identical prompts when the model temperature is set to a high threshold.
    </p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>state-of-the-art</strong></td>
<td>最先进的，最新的</td>
</tr>
<tr>
<td>interpretations</td>
<td>解释，诠释</td>
</tr>
<tr>
<td>complicate</td>
<td>使复杂化</td>
</tr>
<tr>
<td>taxonomy</td>
<td>分类法</td>
</tr>
<tr>
<td>autoregressive</td>
<td>自回归的</td>
</tr>
<tr>
<td>outright</td>
<td>彻底的，完全的</td>
</tr>
<tr>
<td>bloody</td>
<td>血腥的</td>
</tr>
<tr>
<td>circumvent</td>
<td>避开，规避</td>
</tr>
<tr>
<td>uncensored</td>
<td>未审查的</td>
</tr>
<tr>
<td>presumably</td>
<td>据推测，可能</td>
</tr>
<tr>
<td>adversarial</td>
<td>对抗性的，敌对的</td>
</tr>
<tr>
<td>stochastic</td>
<td>随机的</td>
</tr>
<tr>
<td>non-deterministic</td>
<td>非确定性的</td>
</tr>
</tbody></table>
<h3 id="Rosetta-Enabling-Robust-TLS-Encrypted-Traffic-Classification-in-Diverse-Network-Environments-with-TCP-Aware-Traffic-Augmentation"><a href="#Rosetta-Enabling-Robust-TLS-Encrypted-Traffic-Classification-in-Diverse-Network-Environments-with-TCP-Aware-Traffic-Augmentation" class="headerlink" title="Rosetta: Enabling Robust TLS Encrypted Traffic Classification in Diverse Network  Environments with TCP-Aware Traffic Augmentation"></a>Rosetta: Enabling Robust TLS Encrypted Traffic Classification in Diverse Network  Environments with TCP-Aware Traffic Augmentation</h3><blockquote>
<p>Xie R, Wang Y, Cao J, et al. Rosetta: Enabling robust tls encrypted traffic classification in diverse network environments with tcp-aware traffic augmentation[C]&#x2F;&#x2F;Proceedings of the ACM turing award celebration conference-China 2023. 2023: 131-132.</p>
</blockquote>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>The majority of Internet traffic is encrypted using the Transport Layer Security (TLS) protocol. Recent advancements have leveraged Deep Learning (DL) models to classify encrypted traffic by automatically extracting complex and informative features from the packet length sequences of TLS flows. While existing DL models have demonstrated excellent classification results on encrypted traffic, our comprehensive study reveals that they experience significant performance degradation in real-world, diverse network environments. Upon systematically investigating the causes, we discovered that the packet length sequences of flows can change drastically due to various TCP mechanisms used for reliable transmission in different network conditions. To address this, we propose Rosetta, a solution that enhances the robustness of TLS encrypted traffic classification for existing DL models. Rosetta utilizes TCP-aware traffic augmentation mechanisms and self-supervised learning to capture implicit TCP semantics, allowing it to extract more robust features from TLS flows. Extensive experiments show that Rosetta significantly improves the classification performance of existing DL models on TLS traffic in diverse network environments.</p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Transport Layer Security</strong></td>
<td>TLS</td>
</tr>
<tr>
<td><strong>packet length sequences</strong></td>
<td>数据包长度序列</td>
</tr>
<tr>
<td><strong>TCP-aware traffic augmentation mechanism</strong></td>
<td>基于TCP的流量增强机制</td>
</tr>
<tr>
<td>degradation</td>
<td>降级</td>
</tr>
<tr>
<td>augmentation</td>
<td>增强</td>
</tr>
<tr>
<td>semantics</td>
<td>语义</td>
</tr>
</tbody></table>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>Network traffic classification aims to organize various traffic into different categories, which is fundamental and vital for network management and security. A number of network security tasks have been built on top of it, such as application identification [53, 56, 65], website fingerprinting [46, 49, 51, 52], malicious flow detection [33, 37, 38], and user profiling [16, 23]. <br> With the fast-growing need of user privacy protection and the wide usage of the Transport Layer Security (TLS) protocol, a majority of the Internet traffic has been encrypted [12]. Traditional rule-based methods that examine packet payloads are becoming increasingly ineffective in classifying encrypted network traffic [6, 34]. <br> Recent advances [16, 33, 38, 49, 51, 52] are leveraging deep learning (DL) techniques to conduct generic traffic classification. Particularly, as the packet payloads are converted into pseudorandom values after TLS encryption [36], a number of studies [7, 35, 46, 49–51] design various deep learning models to automatically extract complicated and high-level features from packet length sequences, which possess rich and discriminating implicit information of the encrypted flows. <br> Besides, it is convenient and low-cost to measure and derive packet length sequences in real-world large-scale networks, even supporting real-time traffic classification tasks [5, 6]. Though these DL models have been reported to achieve excellent classification results on encrypted traffic [3, 7, 13, 14, 41, 49], e.g., 98% classification accuracy [49], the performance of these models for various traffic classification tasks in the real-world diverse network environments is still not clear. <br> We should note that when they are deployed in a real network for TLS traffic classification, they will face diverse network environments that are time-varying and unpredictable. For example, the packet loss rate and network delay may suddenly arise due to the burst of network traffic [48, 63]. Actually, the environment of one network can be changed complexly due to the joint effect of multiple factors, such as traffic burst [48, 63], traffic engineering [22, 54], partial network failures [2, 64], and network updates [11, 45]. <br> In this paper, we conduct a systematic study to check if existing deep learning models can effectively classify TLS encrypted traffic in diverse network environments. We study six different DL models including Deep Fingerprinting (DF) [51], FS-Net [35], Transformer [57], SDAE [4, 7, 46, 51], CNN [7, 46, 49, 51, 59], and LSTM [7, 46, 51, 59] that rely on packet length sequences to classify encrypted traffic. <br> We conduct experiments not only with the replayed traffic from two typical TLS traffic datasets [19, 39] in diverse network environments, but also with real TLS traffic that is generated by visiting popular websites and running online network applications in diverse Internet environments. <br> Our experiments confirm that all these DL models can achieve excellent results with the offline TLS traffic dataset for various classification tasks, including website fingerprinting, malicious flow identification, VPN traffic identification, and application fingerprinting. However, the performance of all models drops remarkably when they are tested in different network environments, e.g., about 53% accuracy drop at worst.</p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>application identification</strong></td>
<td>应用识别</td>
</tr>
<tr>
<td><strong>website fingerprinting</strong></td>
<td>网站指纹识别</td>
</tr>
<tr>
<td><strong>malicious flow detection</strong></td>
<td>恶意流量检测</td>
</tr>
<tr>
<td><strong>user profiling</strong></td>
<td>用户画像</td>
</tr>
<tr>
<td><strong>real-time traffic classification tasks</strong></td>
<td>实时流量分类任务</td>
</tr>
<tr>
<td><strong>malicious flow identification</strong></td>
<td>恶意流量识别</td>
</tr>
<tr>
<td><strong>VPN traffic identification</strong></td>
<td>VPN 流量识别</td>
</tr>
<tr>
<td><strong>application fingerprinting</strong></td>
<td>应用指纹识别</td>
</tr>
<tr>
<td><strong>traffic engineering</strong></td>
<td>流量工程</td>
</tr>
<tr>
<td><strong>partial network failures</strong></td>
<td>部分网络故障</td>
</tr>
<tr>
<td><strong>network updates</strong></td>
<td>网络更新</td>
</tr>
<tr>
<td><strong>traffic burst</strong></td>
<td>流量突发</td>
</tr>
<tr>
<td>burst</td>
<td>爆发</td>
</tr>
<tr>
<td>payloads</td>
<td>数据负载</td>
</tr>
<tr>
<td>discriminating</td>
<td>区分性的</td>
</tr>
<tr>
<td>implicit</td>
<td>隐含的</td>
</tr>
<tr>
<td>replayed</td>
<td>重放的</td>
</tr>
</tbody></table>
<div class="original-text">
    <div class="content-title">原文内容</div>
    <p>We find that the remarkable performance degradation results from the dramatic change of packet length sequences of the same flow in different network environments. For example, a TLS encrypted flow with the packet length sequence [q1, q2, q3, q4] may change to [q3, q2, q1, q4] due to high packet loss in another network environment. However, existing DL models fail to understand that the two different packet length sequences in different network environments actually originate from the same flow. Furthermore, we notice that the changes of packet length sequences follow the TCP specifications in different network environments, since TLS connections are built on the TCP protocol. Consequently, different TCP mechanisms ensuring reliable transmission in diverse network environments cause three major changes of packet length sequences, i.e., packet subsequence shift, packet subsequence duplication, and packet size variation. Thus, if a model can be aware of these regular packet sequence changes with TCP semantics, robust TLS encrypted traffic classification in diverse network environments may be achieved.</p>
    <p>To this end, we develop Rosetta that is capable of enhancing robust TLS encrypted traffic classification for existing deep learning models. The main idea is to learn implicit TCP semantics from carefully crafted traffic and generate effective feature vectors that represent robust features of TLS flows in diverse network environments. Hence, existing deep learning models can leverage these feature vectors to achieve robust TLS encrypted traffic classification. Rosetta consists of two modules: TCP-aware traffic augmentation and traffic invariant extractor. We develop TCP-aware traffic augmentation algorithms based on a thorough understanding of TCP mechanisms that may affect packet length sequences of flows. Hence, we can generate massive flows that reflect how TLS flows may change in various network environments. The traffic invariant extractor applies self-supervised learning to extract robust features by projecting flow variants into a proper hidden space, reducing the distance among feature vectors of flow variants from the same flow. Consequently, flow variants coming from the same flow will have similar feature vectors.</p>
    <p>We conduct extensive experiments to evaluate the effectiveness of Rosetta. The results show that Rosetta significantly improves the performance of existing deep learning models on traffic classification in diverse network environments with both replayed and real TLS flows. We further evaluate its classification robustness under different packet loss rates and different delays. Without enabling Rosetta, the classification accuracy of existing models drops remarkably when packet loss rates and delays increase. For example, the accuracy drops from 99% to 55% when the delay is increased from 0 to 50 ms. When Rosetta is enabled, the accuracy can always maintain above 86%. Moreover, we compare our TCP-aware traffic augmentation algorithms with classical data augmentation methods, including Random Mask (RM) [17] and Random Swap (RS) [60] that have been widely used in the domains of Natural Language Processing (NLP) and Computer Version (CV). With RM and RS, the average F1-score is less than 47% in six different network environments. With our TCP-aware traffic augmentation, the average F1-score is 87%. The results demonstrate that TCP-aware traffic augmentation is more effective on extracting robust features of TLS flows in different network environments.</p>
</div>

<table>
<thead>
<tr>
<th>术语</th>
<th>翻译</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Natural Language Processing</strong></td>
<td>自然语言处理</td>
</tr>
<tr>
<td><strong>Computer Vision</strong></td>
<td>计算机视觉</td>
</tr>
<tr>
<td>crafted</td>
<td>精心制作</td>
</tr>
<tr>
<td>massive</td>
<td>大量的</td>
</tr>
</tbody></table>
<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3>
    </div>
    <footer class="article-footer">
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BF%9D%E7%A0%94/" rel="tag">保研</a></li></ul>

    </footer>
  </div>
  
  
    
<nav class="article-nav pt-4 mt-3" id="article-nav">
  
    <a href="/2025/07/26/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB1/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          【论文精读】SAGE:Software-based Attestation for GPU Execution
        
      </div>
    </a>
  
  
    <a href="/2025/07/01/algorithm/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">算法题训练</div>
    </a>
  
</nav>


  
</article>
</div>
    </section>
    <footer class="footer pt-5 mt-5">
  <div class="container">
    <div class="py-3">
      <div class="row justify-content-between">
        <div class="col-6">
          <img class="filter-gray mb-3 lazyload" height="40" data-src="/images/DMX_cat.jpg" alt="Hexo" role="img">
          <p class="mb-4"></p>
          <ul class="list-inline">
            
              <li class="list-inline-item">
                <a target="_blank" rel="noopener" href="https://zhwangart.com">
                  <img 0="微博" src="/images/icons/contact_weibo.svg">
                </a>
              </li>
            
              <li class="list-inline-item">
                <a href="javascript:;">
                  <img 0="微信" src="/images/icons/contact_wechat.svg">
                </a>
              </li>
            
              <li class="list-inline-item">
                <a href="mailto:a@abc.com">
                  <img 0="邮箱" src="/images/icons/contact_email.svg">
                </a>
              </li>
            
          </ul>
        </div>
        <div class="col-4">
          <h5>友情链接</h5>
          <ul class="list-inline">
            
              <li class="list-inline-item">
                <a href="https://acorn.imaging.xin/" title="Acorn" target="_blank" rel="noopener">Acorn</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://github.com/" title="GitHub" target="_blank" rel="noopener">GitHub</a>
              </li>
            
              <li class="list-inline-item">
                <a href="https://duoyu.wang/" title="To Base64" target="_blank" rel="noopener">To Base64</a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
    <hr class="hr" style="opacity: .25;">
    <div class="pt-3 pb-5">
      <ul class="list-inline mb-0 text-center">
        <li class="list-inline-item">&copy; 2025 Hexo</li>
        
        <li class="list-inline-item">Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
        <li class="list-inline-item">Designer <a href="https://acorn.imaging.xin/" target="_blank">DM-X~X~X</a></li>
      </ul>
    </div>
  </div>
</footer>
  </main>
  <div id="mobile-nav-dimmer"></div>
<div id="mobile-nav">
	<div id="mobile-nav-inner">
		<ul class="mobile-nav">
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/">首页</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/stories">故事</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/archives">博客</a>
  </li>
  
    
  <li class="nav-item ">
    <a class="nav-item-link" href="/about">关于</a>
  </li>
  
</ul>
		
	</div>
</div>

  <script src="/libs/feather/feather.min.js"></script>
<script src="/libs/lazysizes/lazysizes.min.js"></script>

	<script src="/libs/tocbot/tocbot.min.js"></script>
	<script>
    tocbot.init({
      // Where to render the table of contents.
      tocSelector: '.js-toc',
      // Where to grab the headings to build the table of contents.
      contentSelector: '.js-toc-content',
      // Which headings to grab inside of the contentSelector element.
      headingSelector: 'h2, h3',
      // For headings inside relative or absolute positioned containers within content.
      hasInnerContainers: true,
    });
	</script>





<script src="/js/mobile-nav.js"></script>


<script src="/js/script.js"></script>


</body>
</html>